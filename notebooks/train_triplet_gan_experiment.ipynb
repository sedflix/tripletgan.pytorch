{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as dataset_\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim import Adam\n",
    "from torch.utils import data\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import random\n",
    "\n",
    "from dataset import TripletMNISTDataset\n",
    "from losses import *\n",
    "from model import *\n",
    "from utills import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "    Change this depending on the model\n",
    "\"\"\"\n",
    "out_dimension = 32 # 16 or 32\n",
    "exp_name = \"m_32_2\" # i've used m_32_2 for feature 32 model and m_16 for feature 16 model\n",
    "\n",
    "\n",
    "\n",
    "# this remains pretty constant \n",
    "image_size = 28\n",
    "z_feautures = 100\n",
    "num_epochs = 50\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "\n",
    "# setup dataset\n",
    "normal_mnist_dataset = dataset_.MNIST(root=\"./data\", train=True, download=True,\n",
    "                                      transform=transforms.Compose([\n",
    "                                          transforms.Resize(image_size),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize((.5,), (.5,))\n",
    "                                      ]))\n",
    "triplet_mnist_dataset = TripletMNISTDataset(normal_mnist_dataset, num_samples=60000)\n",
    "\n",
    "# setup loader\n",
    "normal_mnist_dataloader = data.DataLoader(normal_mnist_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "triplet_mnist_dataloader = data.DataLoader(triplet_mnist_dataset, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator and  discriminator\n",
    "generator_net = Generator(z_feautures).to(device)\n",
    "discriminator_net = Discriminator(out_dimension).to(device)\n",
    "\n",
    "# create optimiser for the same\n",
    "discriminator_optimizer = Adam(discriminator_net.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "generator_optimizer = Adam(generator_net.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "# fixed normal noise that is used to generate fake images after sometimes\n",
    "fixed_noise = torch.randn((32, z_feautures, 1, 1), device=device)\n",
    "\n",
    "writer = SummaryWriter(f\"./data/run/{exp_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (generator): Sequential(\n",
       "    (0): ConvTranspose2d(100, 128, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (3): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (6): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (9): ConvTranspose2d(32, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (10): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (discriminator): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (3): Conv2d(16, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (6): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (9): Conv2d(128, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (10): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for visualising the emebeddings in tensorboard\n",
    "special_batch = {\n",
    "    'imgs': [],\n",
    "    'labels': [],\n",
    "    'features': [],\n",
    "}\n",
    "per_class_sample = 10\n",
    "for label in triplet_mnist_dataset.classes:\n",
    "    special_batch['imgs'].extend(random.choices(triplet_mnist_dataset.labels2images[label], k=per_class_sample))\n",
    "    special_batch['labels'].extend([label for _ in range(per_class_sample)])\n",
    "special_batch['imgs'] = torch.cat(special_batch['imgs']).reshape(-1, 1, image_size, image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualisation_imgs = []  # stores visulization of model at the end of each x steps\n",
    "generator_losses = []\n",
    "discriminator_losses = []\n",
    "steps = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (anchor_img, positive_img, negative_img) in enumerate(triplet_mnist_dataloader):\n",
    "        real_imgs, _ = next(iter(normal_mnist_dataloader))\n",
    "        real_imgs = real_imgs.to(device)\n",
    "        anchor_img, positive_img, negative_img = anchor_img.to(device), positive_img.to(device), negative_img.to(device)\n",
    "\n",
    "        \"\"\"\n",
    "            Partially Supervised Discriminator Loss:\n",
    "            Update discriminator net using triplet loss!\n",
    "        \"\"\"\n",
    "        discriminator_net.zero_grad()\n",
    "        anchor_out, positive_out, negative_out = discriminator_net(anchor_img), discriminator_net(\n",
    "            positive_img), discriminator_net(negative_img)\n",
    "        discriminator_loss_triplet = triplet_paper_loss(anchor_out, positive_out, negative_out)\n",
    "        discriminator_loss_triplet.backward()\n",
    "        discriminator_optimizer.step()  # <- Update discriminator\n",
    "\n",
    "        \"\"\"\n",
    "            Unsupervised Discriminator Loss:\n",
    "            Update discriminator net using fake and real data\n",
    "        \"\"\"\n",
    "        discriminator_net.zero_grad()\n",
    "        fake_imgs = generator_net(torch.randn(real_imgs.size(0), z_feautures, 1, 1, device=device))\n",
    "        real_output = discriminator_net(real_imgs.detach())\n",
    "        fake_output = discriminator_net(fake_imgs.detach())\n",
    "        discriminator_loss_unsupervised = f_discriminator_unsupervised_loss(fake_output, real_output)\n",
    "        discriminator_loss_unsupervised.backward()\n",
    "        discriminator_optimizer.step()  # <- Update discriminator\n",
    "\n",
    "        discriminator_loss_total = discriminator_loss_triplet + discriminator_loss_unsupervised\n",
    "\n",
    "        \"\"\"\n",
    "            Update out generator : Done!!\n",
    "        \"\"\"\n",
    "        generator_net.zero_grad()\n",
    "        discriminator_net.zero_grad()\n",
    "\n",
    "        real_output = discriminator_net(real_imgs)\n",
    "        fake_output = discriminator_net(fake_imgs)\n",
    "\n",
    "        # feature_matching_loss has been used as generator_loss\n",
    "        generator_loss = feature_matching_loss(fake_output, real_output)\n",
    "        generator_loss.backward()\n",
    "\n",
    "        generator_optimizer.step()  # <- Update  generator\n",
    "\n",
    "        generator_losses.append(generator_loss.item())\n",
    "        discriminator_losses.append(discriminator_loss_total.item())\n",
    "\n",
    "        writer.add_scalars('Loss', {\n",
    "            'discriminator': discriminator_loss_total.item(),\n",
    "            'generator': generator_loss.item(),\n",
    "        }, steps)\n",
    "        steps = steps + 1\n",
    "\n",
    "        print(\n",
    "            f\"Epoch: {epoch:3d}; Iteration: {i:4d}; \"\n",
    "            f\"Loss D: {discriminator_loss_total.item():0.4f}; \"\n",
    "            f\"Loss G: {generator_loss.item():0.4f}; \",\n",
    "            end=\"\\r\"\n",
    "        )\n",
    "    \n",
    "    \n",
    "    # make images from fixed noise for visualization\n",
    "    with torch.no_grad():\n",
    "        fake_images_with_fixed_noise = generator_net(fixed_noise)\n",
    "    grid = utils.make_grid(fake_images_with_fixed_noise.detach().cpu(), padding=2, normalize=True)\n",
    "    visualisation_imgs.append(grid)\n",
    "    \n",
    "    \n",
    "    # add image to tb\n",
    "    writer.add_image(\"generated image\", grid, steps)\n",
    "    \n",
    "    # write model graphs to tb\n",
    "    #writer.add_graph(generator_net, fixed_noise)\n",
    "    #writer.add_graph(discriminator_net, fake_images_with_fixed_noise)\n",
    "    \n",
    "    # add embedding of b to tb\n",
    "    with torch.no_grad():\n",
    "        special_batch['features'] = discriminator_net(special_batch['imgs'].to(device)).detach().cpu()\n",
    "    writer.add_embedding(special_batch['features'].reshape(-1, out_dimension),\n",
    "                         global_step = steps,\n",
    "                         metadata=special_batch['labels'],\n",
    "                         label_img=special_batch['imgs'])\n",
    "    \n",
    "    \n",
    "    checkpoint(generator_net,\"generator\", exp_name)\n",
    "    checkpoint(discriminator_net,\"discriminator\", exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_losses(generator_losses, discriminator_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_animation(visualisation_imgs, exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-NN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = dataset_.MNIST(root=\"./data\", train=False, download=True,\n",
    "                                      transform=transforms.Compose([\n",
    "                                          transforms.Resize(image_size),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize((.5,), (.5,))\n",
    "                                      ]))\n",
    "train_dataset = dataset_.MNIST(root=\"./data\", train=True, download=True,\n",
    "                                      transform=transforms.Compose([\n",
    "                                          transforms.Resize(image_size),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize((.5,), (.5,))\n",
    "                                      ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./data/discriminator_m_32_2.model for feature vector of 32\n",
    "# ./data/discriminator_m_16.model for feature vector of 16\n",
    "discriminator_net = torch.load(\"./data/discriminator_m_32_2.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(model, dataset, limit=None):\n",
    "    features = []\n",
    "    labels = []\n",
    "    model.eval()\n",
    "    dataloader = data.DataLoader(dataset, batch_size=128, shuffle=False, num_workers=4)\n",
    "    for i, (x, y) in enumerate(dataloader, 1):\n",
    "        x = x\n",
    "        features_batch = list(model(x.to(device)).detach().reshape(-1,model.out_dimension).cpu().numpy())\n",
    "        features.extend(features_batch)   \n",
    "        labels.extend(y)\n",
    "        \n",
    "        if limit is not None:\n",
    "            if (i*128) > limit:\n",
    "                break\n",
    "                \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = get_features(discriminator_net, test_dataset, None)\n",
    "x_train, y_train = get_features(discriminator_net, train_dataset, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for number of train samples to be used\n",
    "N = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = x_train[:N], y_train[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knn= KNeighborsClassifier(n_neighbors=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=9, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9903"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_binary = label_binarize(y_test, classes=[i for i in range(10)])\n",
    "average_precision_score(y_test_binary, knn.predict_proba(x_test), average=\"samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Results\n",
    "- M32: 100: 0.9903, 0.992535\n",
    "- M32: 200: 0.9911, 0.9908\n",
    "\n",
    "- M16: 100: 0.989, 0.99151\n",
    "- M16: 200: 0.9898, 0.99178"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
